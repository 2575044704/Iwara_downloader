#!/usr/bin/env python3
"""
ç»Ÿè®¡æ‰€æœ‰chunkæ–‡ä»¶ä¸­è§†é¢‘çš„æ€»å¤§å°
ç²¾ç¡®åˆ°MB
"""

import json
import sys
from pathlib import Path
from decimal import Decimal, ROUND_HALF_UP

def bytes_to_mb(bytes_value):
    """å°†å­—èŠ‚è½¬æ¢ä¸ºMBï¼Œä¿ç•™2ä½å°æ•°"""
    mb = Decimal(bytes_value) / Decimal(1024 * 1024)
    return mb.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)

def bytes_to_human(bytes_value):
    """å°†å­—èŠ‚è½¬æ¢ä¸ºäººç±»å¯è¯»æ ¼å¼"""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB', 'PB']:
        if bytes_value < 1024.0:
            return f"{bytes_value:.2f} {unit}"
        bytes_value /= 1024.0
    return f"{bytes_value:.2f} PB"

def calculate_chunk_size(chunk_file):
    """è®¡ç®—å•ä¸ªchunkæ–‡ä»¶ä¸­æ‰€æœ‰è§†é¢‘çš„æ€»å¤§å°"""
    try:
        with open(chunk_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if not isinstance(data, dict) or "videos" not in data:
            print(f"  âš ï¸  {chunk_file.name} æ ¼å¼é”™è¯¯")
            return 0, 0
        
        videos = data["videos"]
        total_size = 0
        video_count = 0
        
        for video in videos:
            file_info = video.get("file")
            if file_info and isinstance(file_info, dict):
                size = file_info.get("size", 0)
                if size > 0:
                    total_size += size
                    video_count += 1
        
        return total_size, video_count
        
    except Exception as e:
        print(f"  âŒ è¯»å– {chunk_file.name} å¤±è´¥: {e}")
        return 0, 0

def calculate_total_size(directory):
    """è®¡ç®—ç›®å½•ä¸­æ‰€æœ‰chunkæ–‡ä»¶çš„è§†é¢‘æ€»å¤§å°"""
    dir_path = Path(directory)
    
    if not dir_path.exists():
        print(f"é”™è¯¯ï¼šç›®å½•ä¸å­˜åœ¨ - {directory}")
        return
    
    # æ‰¾åˆ°æ‰€æœ‰chunkæ–‡ä»¶
    chunk_files = sorted(dir_path.glob("chunk_*.json"))
    
    if not chunk_files:
        print(f"é”™è¯¯ï¼šåœ¨ {directory} ä¸­æ²¡æœ‰æ‰¾åˆ°chunkæ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(chunk_files)} ä¸ªchunkæ–‡ä»¶")
    print("=" * 80)
    
    # ç»Ÿè®¡å˜é‡
    grand_total_bytes = 0
    grand_total_videos = 0
    chunk_stats = []
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    print("æ­£åœ¨è®¡ç®—...")
    for i, chunk_file in enumerate(chunk_files):
        chunk_size, video_count = calculate_chunk_size(chunk_file)
        grand_total_bytes += chunk_size
        grand_total_videos += video_count
        
        chunk_stats.append({
            "name": chunk_file.name,
            "size": chunk_size,
            "size_mb": float(bytes_to_mb(chunk_size)),
            "videos": video_count
        })
        
        # æ˜¾ç¤ºè¿›åº¦
        print(f"  [{i+1}/{len(chunk_files)}] {chunk_file.name}: "
              f"{video_count} ä¸ªè§†é¢‘, {bytes_to_human(chunk_size)}")
    
    # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
    print("\n" + "=" * 80)
    print("ğŸ“Š è¯¦ç»†ç»Ÿè®¡:")
    print(f"{'æ–‡ä»¶å':<20} {'è§†é¢‘æ•°':>8} {'å¤§å°(MB)':>15} {'å¤§å°(GB)':>12}")
    print("-" * 60)
    
    for stat in chunk_stats:
        gb_size = stat["size_mb"] / 1024
        print(f"{stat['name']:<20} {stat['videos']:>8} {stat['size_mb']:>15,.2f} {gb_size:>12,.2f}")
    
    # æ˜¾ç¤ºæ€»è®¡
    print("-" * 60)
    total_mb = float(bytes_to_mb(grand_total_bytes))
    total_gb = total_mb / 1024
    total_tb = total_gb / 1024
    
    print(f"{'æ€»è®¡':<20} {grand_total_videos:>8} {total_mb:>15,.2f} {total_gb:>12,.2f}")
    
    # æ˜¾ç¤ºæ±‡æ€»
    print("\n" + "=" * 80)
    print("ğŸ“ˆ æ±‡æ€»ä¿¡æ¯:")
    print(f"  æ–‡ä»¶æ•°é‡: {len(chunk_files)} ä¸ª")
    print(f"  è§†é¢‘æ€»æ•°: {grand_total_videos:,} ä¸ª")
    print(f"  å¹³å‡æ¯ä¸ªæ–‡ä»¶: {grand_total_videos/len(chunk_files):.0f} ä¸ªè§†é¢‘")
    print(f"\n  æ€»å¤§å°ç»Ÿè®¡:")
    print(f"    å­—èŠ‚(Bytes): {grand_total_bytes:,}")
    print(f"    å…†å­—èŠ‚(MB): {total_mb:,.2f}")
    print(f"    å‰å­—èŠ‚(GB): {total_gb:,.2f}")
    print(f"    å¤ªå­—èŠ‚(TB): {total_tb:,.2f}")
    
    # è®¡ç®—å¹³å‡å€¼
    if grand_total_videos > 0:
        avg_size_bytes = grand_total_bytes / grand_total_videos
        avg_size_mb = float(bytes_to_mb(avg_size_bytes))
        print(f"\n  å¹³å‡æ¯ä¸ªè§†é¢‘:")
        print(f"    å¤§å°: {bytes_to_human(avg_size_bytes)} ({avg_size_mb:.2f} MB)")
    
    # ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
    report = {
        "directory": str(dir_path),
        "chunk_files": len(chunk_files),
        "total_videos": grand_total_videos,
        "total_size": {
            "bytes": grand_total_bytes,
            "mb": total_mb,
            "gb": total_gb,
            "tb": total_tb
        },
        "average_per_video": {
            "bytes": int(avg_size_bytes) if grand_total_videos > 0 else 0,
            "mb": avg_size_mb if grand_total_videos > 0 else 0
        },
        "chunk_details": chunk_stats
    }
    
    report_path = dir_path / "size_statistics.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

def main():
    if len(sys.argv) > 1 and sys.argv[1] in ['-h', '--help']:
        print("ç»Ÿè®¡æ‰€æœ‰è§†é¢‘æ€»å¤§å°")
        print("\nç”¨æ³•:")
        print("  python calculate_size.py [ç›®å½•è·¯å¾„]")
        print("\nç¤ºä¾‹:")
        print("  python calculate_size.py /iwara_data_pured")
        return
    
    # é»˜è®¤è·¯å¾„
    directory = "/__modal/volumes/vo-ieu7V88l04V1sGny7d7ebd/iwara_data_pured"
    
    if len(sys.argv) > 1:
        directory = sys.argv[1]
    
    print(f"ç»Ÿè®¡ç›®å½•: {directory}")
    calculate_total_size(directory)

if __name__ == "__main__":
    main()